{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWjTV_QnxMxa"
   },
   "source": [
    "This notebook is to be run in Kaggle. To access the data, please add the dataset from the following link www.kaggle.com/dataset/7a3aa98e18ee9bc22957ef4f78ac001358c3b3a9c69ea4d99366a8c7fa0e144d to your kernel/Kaggle account and the trained model weights included with this notebook to see predictions without training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZF2tdRJga8M"
   },
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "088fd178-d59d-44ad-a596-e8169662eff2",
    "_uuid": "190d4747-335d-4547-9acc-2dd84c66add3",
    "id": "eMES8984aww9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxjoXuhlgdbk"
   },
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8e207cc7-336c-42ac-a598-dcd411e426a5",
    "_uuid": "8c4f2a67-7dd9-4b96-9b78-9511c8e650b0",
    "id": "or1SZaigawxH"
   },
   "outputs": [],
   "source": [
    "x_wid, y_wid = (224, 224) # (96,96)\n",
    "n_channels = 3\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4o1jSsAWxMxl"
   },
   "outputs": [],
   "source": [
    "%ls '../input'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7wcHTSJawxM"
   },
   "outputs": [],
   "source": [
    "train_dir = '../input/fhisto/train'\n",
    "val_dir = '../input/fhisto/val'\n",
    "test_dir = '../input/fhisto/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OSP-0Py3gjYu"
   },
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ofx97Nwclk7w"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "55619b25-ea92-4f99-bd76-7434db38f609",
    "_uuid": "a75584b4-9aae-4667-a0fd-80afc99c6905",
    "id": "7gFhb_0Qawxh"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function = preprocess_input,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True\n",
    "        )\n",
    "\n",
    "val_datagen = ImageDataGenerator(\n",
    "        preprocessing_function = preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(x_wid, y_wid),\n",
    "        color_mode='rgb',\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary'\n",
    "        )\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(x_wid, y_wid),\n",
    "        batch_size=batch_size,\n",
    "        color_mode='rgb',\n",
    "        class_mode='binary'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FIlpa-hExMxy"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "#plotting rondom images from dataset\n",
    "def class_plot(data , n_figures = 12):\n",
    "    n_row = int(n_figures/4)\n",
    "    fig,axes = plt.subplots(figsize=(14, 10), nrows = n_row, ncols=4)\n",
    "    for ax in axes.flatten():\n",
    "        a = random.randint(0,len(data))\n",
    "        (img,lbl) = data[a]\n",
    "        #print(lbl)\n",
    "        for label,image in zip(lbl,img):\n",
    "          if label==1.:\n",
    "            l='malignant'\n",
    "          elif label==0.:\n",
    "            l='benign'\n",
    "          image=np.array(image).astype(np.uint8)     \n",
    "          im = ax.imshow(image)\n",
    "          ax.set_title(l)\n",
    "          ax.axis('off')\n",
    "        pass\n",
    "        \n",
    "    plt.show()\n",
    "class_plot(train_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jLOBFxEIghBX"
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hd0Wd56_k6XR"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, GlobalAveragePooling2D, GlobalMaxPooling2D, Concatenate, BatchNormalization, Dropout, Dense\n",
    "from keras.models import Model\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CptKk0OYawyX"
   },
   "outputs": [],
   "source": [
    "sz = (x_wid,y_wid,n_channels)\n",
    "base_model = ResNet50(weights=\"imagenet\", input_shape=sz, input_tensor=Input(sz), include_top=False)\n",
    "\n",
    "model_name='resnet50'\n",
    "\n",
    "avg = GlobalAveragePooling2D()(base_model.output)\n",
    "mx = GlobalMaxPooling2D()(base_model.output)\n",
    "out = Concatenate()([avg, mx])\n",
    "out = BatchNormalization()(out)\n",
    "out = Dropout(0.25)(out)\n",
    "out = Dense(512, activation=\"relu\")(out)\n",
    "out = BatchNormalization()(out)\n",
    "out = Dropout(0.5)(out)\n",
    "out = Dense(1, activation=\"sigmoid\")(out)\n",
    "model = Model(inputs=base_model.input, outputs=out)\n",
    "\n",
    "for layer in base_model.layers:    \n",
    "    if layer.name[-2:]=='bn':\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "optimizer = Adam(lr=0.01)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uj5beD2xgrJH"
   },
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "dfd25fdd-a107-4777-b65c-534d9e84f43c",
    "_uuid": "e3391030-1476-4f44-afce-2bc6955e2c6b",
    "id": "6rCrTN5Vawx0"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "filepath = model_name+'_full_weights.{epoch:02d}-{val_loss:.2f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', min_delta=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20)\n",
    "csv_logger = CSVLogger('log'+model_name+'.csv', append=True, separator=';')\n",
    "    \n",
    "callbacks_list = [csv_logger, checkpoint, reduceLROnPlat, early]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_YFz1OrhPE1"
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZcKGl7kLawyc"
   },
   "outputs": [],
   "source": [
    "loss_history = model.fit_generator(train_generator,\n",
    "    steps_per_epoch = train_generator.samples // batch_size,\n",
    "    validation_data = validation_generator, \n",
    "    validation_steps = validation_generator.samples // batch_size,\n",
    "    epochs = 30,\n",
    "    callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f08dab98-7f22-4f9e-a0b2-6b06ece78679",
    "_uuid": "9c1bc160-b692-481f-9344-75fdf948c8c2",
    "id": "GA5c5raGawx5"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    ## Accuracy\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0SKlxCz7guiF"
   },
   "source": [
    "# Plot Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2631040d-ce64-4bac-a755-29ed16b7a517",
    "_uuid": "341687e2-ae84-4597-9225-0fe4fa824f8e",
    "id": "KF-LLJsFawx8"
   },
   "outputs": [],
   "source": [
    "plot_history(loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-A-XVHZxMyJ"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QE3GgX5WxMyJ"
   },
   "outputs": [],
   "source": [
    "model.load_weights('../input/resnet50weights.30-0.13.hdf5.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HvisubyxxMyL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "prediction_filename=model_name+'test_pred'\n",
    "threshold=0.5\n",
    "test_samples=os.listdir(test_dir)\n",
    "ID=[]\n",
    "test_predictions=[]\n",
    "\n",
    "for i in test_samples:\n",
    "    image = load_img(os.path.join(test_dir,i), target_size=(224, 224))\n",
    "    print(i)\n",
    "    # convert the image to an array\n",
    "    img = img_to_array(image)\n",
    "    print(img.shape)\n",
    "    # expand dimensions so that it represents a single 'sample'\n",
    "\n",
    "    image_norm = np.expand_dims(img, axis=0)\n",
    "    image_norm = preprocess_input(image_norm)\n",
    "    pred = model.predict(image_norm)\n",
    "    print(pred[0,0])\n",
    "    if pred > threshold:\n",
    "        lbl=1\n",
    "    else:\n",
    "        lbl=0\n",
    "    ID.append(str(i))\n",
    "    test_predictions.append(lbl)\n",
    "\n",
    "TP=pd.DataFrame(list(zip(ID, test_predictions)),\n",
    "columns=['id','prediction'])\n",
    "TP.to_csv(prediction_filename+\".csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e2a52d56-6ea3-4d52-aa9b-819dcea7681d",
    "_uuid": "8dee91d3-769f-4437-8539-dcb41bc7f4ce",
    "id": "1ehoD1ciawye"
   },
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c5623b08-3d92-4841-81f3-887432ec73d9",
    "_uuid": "39c560d5-28c7-485a-bf99-20f3cf386a3c",
    "id": "bXlILsprawye"
   },
   "outputs": [],
   "source": [
    "!pip install torchsummary\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm.autonotebook import tqdm\n",
    "def normalization_parameter(dataloader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    nb_samples = len(dataloader.dataset)\n",
    "    for data,_ in tqdm(dataloader):\n",
    "        batch_samples = data.size(0)\n",
    "        data = data.view(batch_samples, data.size(1), -1)\n",
    "        mean += data.mean(2).sum(0)\n",
    "        std += data.std(2).sum(0)\n",
    "    mean /= nb_samples\n",
    "    std /= nb_samples\n",
    "    return mean.numpy(), std.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c82a6de8-5acb-4c4a-8d69-939872ffc8fe",
    "_uuid": "b72582cf-2442-493e-8c48-4d3042962836",
    "id": "ocKRAFV3awyj"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "mean = np.array([0.70039797, 0.5381607, 0.6912888])\n",
    "std = np.array([0.18225521, 0.20144886, 0.16523378])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hn95Y1Q3htxl"
   },
   "source": [
    "## Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "26358392-8c79-492d-9615-3d4b9df9d763",
    "_uuid": "7e4b0f1c-61aa-4618-b1f0-d3ec0b1c6a39",
    "id": "PmLkXUuxawyn"
   },
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "                                        transforms.RandomHorizontalFlip(), \n",
    "                                        transforms.RandomVerticalFlip(),\n",
    "                                        transforms.RandomRotation(20),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean,std)])\n",
    "test_transform = transforms.Compose([\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean,std)])\n",
    "#inverse normalization for image plot\n",
    "inv_normalize = transforms.Normalize(\n",
    "    mean=-1*np.divide(mean,std),\n",
    "    std=1/std\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztb_EGxxhwAQ"
   },
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "af169849-1f88-4050-825a-a5419ccf693f",
    "_uuid": "49c59ba5-52b1-4786-9b38-e57b7f7c2e40",
    "id": "4k1NdP-7awyq"
   },
   "outputs": [],
   "source": [
    "def data_loader(train_data, test_data, valid_size, batch_size=128):\n",
    "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    data_len = len(test_data)\n",
    "    indices = list(range(data_len))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    split1 = int(np.floor(valid_size * data_len))\n",
    "    valid_idx, test_idx = indices[:split1], indices[split1:]\n",
    "    \n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    \n",
    "    valid_loader = DataLoader(test_data, batch_size= batch_size, sampler=valid_sampler)\n",
    "    test_loader = DataLoader(test_data, batch_size= batch_size, sampler=test_sampler)\n",
    "    \n",
    "    loader = {'train': train_loader, 'val': valid_loader, 'test': test_loader}\n",
    "    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "58ab0c55-8464-4a94-b287-7a846dd5edd9",
    "_uuid": "2212ad2e-e1c5-44f3-a331-07ace574a72c",
    "id": "4_y67YXDawyt"
   },
   "outputs": [],
   "source": [
    "train_data = ImageFolder(root='../input/histopathology/train', transform=train_transform)\n",
    "test_data = ImageFolder(root='../input/histopathology/val', transform=test_transform)\n",
    "\n",
    "loader = data_loader(train_data, test_data, valid_size=0.2, batch_size=batch_size)\n",
    "\n",
    "#label of classes\n",
    "classes = train_data.classes\n",
    "#encoder and decoder to convert classes into integer\n",
    "decoder = {}\n",
    "for i in range(len(classes)):\n",
    "    decoder[classes[i]] = i\n",
    "encoder = {}\n",
    "for i in range(len(classes)):\n",
    "    encoder[i] = classes[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdzWaPtNhyqz"
   },
   "source": [
    "## Plot Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "865a4230-e59d-49da-a4ab-975497936221",
    "_uuid": "cfe173b0-f20a-4c95-887b-fd988350cfeb",
    "id": "8oy0RfE2awyv"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "#plotting rondom images from dataset\n",
    "def class_plot(data, encoder, inv_normalize = None, n_figures = 12):\n",
    "    n_row = int(n_figures/4)\n",
    "    fig,axes = plt.subplots(figsize=(14, 10), nrows = n_row, ncols=4)\n",
    "    for ax in axes.flatten():\n",
    "        a = random.randint(0,len(data))\n",
    "        (image,label) = data[a]\n",
    "        print(type(image))\n",
    "        label = int(label)\n",
    "        l = encoder[label]\n",
    "        if(inv_normalize!=None):\n",
    "            image = inv_normalize(image)\n",
    "        \n",
    "        image = image.numpy().transpose(1,2,0)\n",
    "        im = ax.imshow(image)\n",
    "        ax.set_title(l)\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "class_plot(train_data,encoder,inv_normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5M3iDsfh4B9"
   },
   "source": [
    "## Set GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8c1d812a-bc25-4a7b-9b21-958648622d18",
    "_uuid": "10e98345-4872-4bc6-93bd-6f961ca2d961",
    "id": "2KYaQ4Ipawyw"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q_6lb6lBh9nn"
   },
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f1901671-dd3d-4c5e-a074-0572e242235c",
    "_uuid": "ec8e9901-5184-4873-926d-c00d9aad5f5a",
    "id": "9skos9jHawy1"
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Px87lxnvh_2X"
   },
   "source": [
    "## Cyclical LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "29280bd0-3f66-4678-9041-f80aedc755a6",
    "_uuid": "2d6ed823-22b0-4218-86d9-9d78568e66c0",
    "id": "Sh1qE0PIawy4"
   },
   "outputs": [],
   "source": [
    "def cyclical_lr(stepsize, min_lr=3e-4, max_lr=3e-3):\n",
    "\n",
    "    # Scaler: we can adapt this if we do not want the triangular CLR\n",
    "    scaler = lambda x: 1.\n",
    "\n",
    "    # Lambda function to calculate the LR\n",
    "    lr_lambda = lambda it: min_lr + (max_lr - min_lr) * relative(it, stepsize)\n",
    "\n",
    "    # Additional function to see where on the cycle we are\n",
    "    def relative(it, stepsize):\n",
    "        cycle = math.floor(1 + it / (2 * stepsize))\n",
    "        x = abs(it / stepsize - 2 * cycle + 1)\n",
    "        return max(0, (1 - x)) * scaler(cycle)\n",
    "\n",
    "    return lr_lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O70l1-XfiBd5"
   },
   "source": [
    "## Plot Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b892cef9-f54b-4699-b53d-63112ec15c9a",
    "_uuid": "87aec935-a3d1-4c4d-82d1-dfc4ac16c15e",
    "id": "8B0YnOyZawy_"
   },
   "outputs": [],
   "source": [
    "def error_plot(loss):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(loss)\n",
    "    plt.title(\"Training loss plot\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "def acc_plot(acc):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(acc)\n",
    "    plt.title(\"Training accuracy plot\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.show()\n",
    "# To plot the wrong predictions given by model\n",
    "def wrong_plot(n_figures,true,ima,pred,encoder,inv_normalize):\n",
    "    print('Classes in order Actual and Predicted')\n",
    "    n_row = int(n_figures/3)\n",
    "    fig,axes = plt.subplots(figsize=(14, 10), nrows = n_row, ncols=3)\n",
    "    for ax in axes.flatten():\n",
    "        a = random.randint(0,len(true)-1)\n",
    "    \n",
    "        image,correct,wrong = ima[a],true[a],pred[a]\n",
    "        image = torch.from_numpy(image)\n",
    "        correct = int(correct)\n",
    "        c = encoder[correct]\n",
    "        wrong = int(wrong)\n",
    "        w = encoder[wrong]\n",
    "        f = 'A:'+c + ',' +'P:'+w\n",
    "        if inv_normalize !=None:\n",
    "            image = inv_normalize(image)\n",
    "        image = image.numpy().transpose(1,2,0)\n",
    "        im = ax.imshow(image)\n",
    "        ax.set_title(f)\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "def performance_matrix(true,pred):\n",
    "    precision = metrics.precision_score(true,pred,average='macro')\n",
    "    recall = metrics.recall_score(true,pred,average='macro')\n",
    "    accuracy = metrics.accuracy_score(true,pred)\n",
    "    f1_score = metrics.f1_score(true,pred,average='macro')\n",
    "    print('Precision: {} Recall: {}, Accuracy: {}: ,f1_score: {}'.format(precision*100,recall*100,accuracy*100,f1_score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VL00qPyiJHi"
   },
   "source": [
    "## Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "76325d72-e9ae-4b21-a0d4-f2ad3c9a011d",
    "_uuid": "393764a0-5b67-4bf3-ad07-418bf5159890",
    "id": "qv_ys_gMawzA"
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "lr = 0.0005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3VDqw5CiG8a"
   },
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzQowaqWawzF"
   },
   "outputs": [],
   "source": [
    "resnet = models.resnet34().to(device)\n",
    "print(resnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bb9dp95tiSt_"
   },
   "source": [
    "## Fine-tune Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A0X6uFTLawzH"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# https://docs.fast.ai/layers.html#AdaptiveConcatPool2d\n",
    "class AdaptiveConcatPool2d(nn.Module):\n",
    "    def __init__(self, size=1):\n",
    "        super().__init__()\n",
    "        self.output_size = size\n",
    "        self.ap = nn.AdaptiveAvgPool2d(size)\n",
    "        self.mp = nn.AdaptiveMaxPool2d(size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.mp(x), self.ap(x)], 1)\n",
    "\n",
    "# https://docs.fast.ai/layers.html#Flatten\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "    \n",
    "in_features = resnet.fc.in_features * 2    \n",
    "num_hidden = 512\n",
    "\n",
    "head = nn.Sequential(\n",
    "    AdaptiveConcatPool2d(1),\n",
    "    Flatten(),\n",
    "    nn.BatchNorm1d(in_features),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=in_features, out_features=num_hidden),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(num_hidden),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(in_features=num_hidden, out_features=2),\n",
    ")\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Sequential(*list(resnet.children())[:-2]),\n",
    "    head\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBoPcot5iXuo"
   },
   "source": [
    "## Training & Validation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qoMvgBigawzJ"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, scheduler, cyclic):\n",
    "    total_loss = 0.0\n",
    "    num_batches = len(train_loader)\n",
    "    size = num_batches * batch_size\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        print(f\"Training: {i}/{num_batches}\", end=\"\\r\")\n",
    "        \n",
    "        scheduler.step()\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images) # forward pass\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        loss.backward()  # backprogagation\n",
    "        optimizer.step()\n",
    "        if cyclic:\n",
    "            # Update LR\n",
    "            scheduler.step()\n",
    "        \n",
    "    return total_loss / size\n",
    "\n",
    "def validate(valid_loader, model, criterion):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_correct = 0\n",
    "        total_loss = 0.0\n",
    "        num_batches = len(valid_loader)\n",
    "        size = num_batches * batch_size\n",
    "        for i, (images, labels) in enumerate(valid_loader):\n",
    "            print(f\"Validation: {i}/{num_batches}\", end=\"\\r\")\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total_correct += torch.sum(preds == labels.data)\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            \n",
    "        return total_loss / size, total_correct.double() / size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bk8x4AMtiiCH"
   },
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7Rw2KkDawzL"
   },
   "outputs": [],
   "source": [
    "def fit(model, num_epochs, train_loader, valid_loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=1e-2, steps_per_epoch=len(train_loader), epochs=num_epochs)\n",
    "    cyclic = False\n",
    "    if cyclic:\n",
    "        factor=10\n",
    "        end_lr=0.001\n",
    "        step_size = 4*len(loader['train'])\n",
    "        clr = cyclical_lr(step_size, min_lr=end_lr/factor, max_lr=end_lr)\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, [clr])\n",
    "\n",
    "        # Make lists to capture the logs\n",
    "        lr_find_lr = []\n",
    "    print(\"epoch\\ttrain loss\\tvalid loss\\taccuracy\")\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(train_loader, model, criterion, optimizer, scheduler, cyclic)\n",
    "        valid_loss, valid_acc = validate(valid_loader, model, criterion)\n",
    "        print(f\"{epoch}\\t{train_loss:.5f}\\t\\t{valid_loss:.5f}\\t\\t{valid_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uKxd3p3eawzO"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "fit(model, 20, loader['train'], loader['val'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "histopathology.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
